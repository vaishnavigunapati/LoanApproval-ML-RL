{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6325dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (50000, 8)\n",
      "2025-09-05 14:25.42 [info     ] Signatures have been automatically determined. action_signature=Signature(dtype=[dtype('int64')], shape=[(1,)]) observation_signature=Signature(dtype=[dtype('float32')], shape=[(7,)]) reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)])\n",
      "2025-09-05 14:25.42 [info     ] Action-space has been automatically determined. action_space=<ActionSpace.DISCRETE: 2>\n",
      "2025-09-05 14:25.43 [info     ] Action size has been automatically determined. action_size=2\n",
      "\n",
      "âœ… RL dataset created, size: 50000\n",
      "2025-09-05 14:25.43 [info     ] dataset info                   dataset_info=DatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(7,)]), action_signature=Signature(dtype=[dtype('int64')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\n",
      "2025-09-05 14:25.43 [warning  ] Skip building models since they're already built.\n",
      "2025-09-05 14:25.43 [info     ] Directory is created at d3rlpy_logs\\DiscreteBC_20250905142543\n",
      "2025-09-05 14:25.43 [info     ] Parameters                     params={'observation_shape': [7], 'action_size': 2, 'config': {'type': 'discrete_bc', 'params': {'batch_size': 100, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.001, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'beta': 0.5}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:50<00:00, 199.92it/s, loss=0.748, imitation_loss=0.389, regularization_loss=0.359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-05 14:26.33 [info     ] DiscreteBC_20250905142543: epoch=1 step=10000 epoch=1 metrics={'time_sample_batch': 0.001182298994064331, 'time_algorithm_update': 0.003563978672027588, 'loss': 0.7477409408986568, 'imitation_loss': 0.38867263781428335, 'regularization_loss': 0.3590683028638363, 'time_step': 0.00494197359085083} step=10000\n",
      "2025-09-05 14:26.33 [info     ] Model parameters are saved to d3rlpy_logs\\DiscreteBC_20250905142543\\model_10000.d3\n",
      "\n",
      "ðŸ¤– RL Agent Results (DiscreteBC):\n",
      "Estimated Policy Value: 0.1046\n"
     ]
    }
   ],
   "source": [
    "# loan_rl_agent.ipynb (or .py if script)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "from d3rlpy.algos import DiscreteBC, DiscreteBCConfig\n",
    "\n",
    "# ------------------------\n",
    "# 1. Load & Preprocess Data\n",
    "# ------------------------\n",
    "CSV_PATH = r\"C:\\Users\\Relig\\Downloads\\LoanApproval-ML-RL\\data\\accepted_2007_to_2018.csv\"\n",
    "SAMPLE_N = 50000\n",
    "\n",
    "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
    "df = df[df['loan_status'].isin(['Fully Paid', 'Charged Off'])].copy()\n",
    "df['loan_status'] = df['loan_status'].map({'Fully Paid': 0, 'Charged Off': 1})\n",
    "\n",
    "# clean numerics\n",
    "df['loan_amnt'] = pd.to_numeric(df['loan_amnt'], errors='coerce')\n",
    "df['int_rate'] = df['int_rate'].astype(str).str.rstrip('%').replace('nan', np.nan)\n",
    "df['int_rate'] = pd.to_numeric(df['int_rate'], errors='coerce') / 100.0\n",
    "df['annual_inc'] = pd.to_numeric(df['annual_inc'], errors='coerce')\n",
    "df['dti'] = pd.to_numeric(df['dti'], errors='coerce')\n",
    "\n",
    "df = df[['loan_amnt','int_rate','annual_inc','dti',\n",
    "         'emp_length','home_ownership','purpose','loan_status']].dropna()\n",
    "\n",
    "loan_amnt_orig = df['loan_amnt'].values.copy()\n",
    "int_rate_orig  = df['int_rate'].values.copy()\n",
    "\n",
    "features = ['loan_amnt','int_rate','annual_inc','dti',\n",
    "            'emp_length','home_ownership','purpose']\n",
    "\n",
    "for col in ['emp_length','home_ownership','purpose']:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "if len(df) > SAMPLE_N:\n",
    "    df = df.sample(n=SAMPLE_N, random_state=42).reset_index(drop=True)\n",
    "    loan_amnt_orig = df['loan_amnt'].values\n",
    "    int_rate_orig  = df['int_rate'].values\n",
    "\n",
    "print(\"Final dataset shape:\", df.shape)\n",
    "\n",
    "# ------------------------\n",
    "# 2. Build RL Dataset\n",
    "# ------------------------\n",
    "states = df[features].values.astype(np.float32)\n",
    "actions = np.ones(len(df), dtype=np.int64)  # dataset logs approvals\n",
    "rewards = np.where(df['loan_status'].values == 0,\n",
    "                   loan_amnt_orig * int_rate_orig,\n",
    "                   -loan_amnt_orig).astype(np.float32)\n",
    "terminals = np.ones(len(df), dtype=bool)\n",
    "\n",
    "rl_dataset = MDPDataset(states, actions, rewards, terminals)\n",
    "print(\"\\nâœ… RL dataset created, size:\", rl_dataset.size())\n",
    "\n",
    "# ------------------------\n",
    "# 3. Train RL Agent (DiscreteBC)\n",
    "# ------------------------\n",
    "bc_config = DiscreteBCConfig()\n",
    "bc = DiscreteBC(config=bc_config, device=\"cpu\", enable_ddp=False)\n",
    "\n",
    "bc.build_with_dataset(rl_dataset)\n",
    "\n",
    "bc.fit(\n",
    "    dataset=rl_dataset,\n",
    "    n_steps=10000\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# 4. Evaluate Policy Value\n",
    "# ------------------------\n",
    "pred_actions = bc.predict(states[:1000])\n",
    "\n",
    "chosen_rewards = []\n",
    "for s, a in zip(states[:1000], pred_actions):\n",
    "    if a == 1:  # approve\n",
    "        idx = np.random.randint(len(rewards))\n",
    "        chosen_rewards.append(rewards[idx])\n",
    "    else:       # deny\n",
    "        chosen_rewards.append(0.0)\n",
    "\n",
    "policy_value = np.mean(chosen_rewards)\n",
    "\n",
    "print(\"\\nðŸ¤– RL Agent Results (DiscreteBC):\")\n",
    "print(\"Estimated Policy Value:\", round(policy_value, 4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
